---
layout: page
title: Tokenization
nav_exclude: true
permalink: /notes/token/
---

# Tokenization

Tokenization is a process that splits text and document into small parts by using white space and punctuation.

Example Sentence: <br>
"I would like to learn an NLP course."  <br>

Tokens: <br>

"I", "would", "like", "to", "learn", "an", "NLP", "course", "."
